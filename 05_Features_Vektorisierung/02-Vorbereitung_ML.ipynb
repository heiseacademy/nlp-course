{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vorbereitung Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bevor du mit dem Machine Learning beginnen kannst, musst du einige Vorbereitungen treffen.\n",
    "\n",
    "Einiges davon hast du schon erledigt, so sind z.B. die Dokumente bereits tokenisiert und die linguistische Analyse hast du auch durchgeführt. Dadurch kennst du die unterschiedlichen Wortarten.\n",
    "\n",
    "Es bleiben aber noch einige Entscheidungen zu treffen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einladen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuerst lädst du die Daten wie gewohnt ein. Du benutzt die Tabelle `nlp_articles`, um alle Freiheiten bzgl. der Daten (bzw. Tokens) zu haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    os.system(\"test -f heise-articles-2020.db || wget  https://datanizing.com/heiseacademy/nlp-course/blob/main/99_Common/heise-articles-2020.db.gz && gunzip heise-articles-2020.db.gz\")\n",
    "    newsticker_db = 'heise-articles-2020.db'\n",
    "else:\n",
    "    newsticker_db = '../99_Common/heise-articles-2020.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 \n",
    "import pandas as pd\n",
    "\n",
    "sql = sqlite3.connect(newsticker_db)\n",
    "df = pd.read_sql(\"SELECT * FROM nlp_articles\", sql, index_col=\"id\", parse_dates=[\"datePublished\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anzahl der Dokumente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welche Entitäten analysieren?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun gibt es verschiedene Varianten, was du analysieren möchtest:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Überschriften"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du könntest dich an erster Stelle für die Überschriften interessieren. Das ist besonders dann spannend, wenn du dich dafür interessierst, welche Überschriften angeklickt werden. In diesem Moment kennen die User ja den Text noch gar nicht - sie sehen nur die Überschriften. Deswegen wäre es dann genau richtig, nur diese zu analysieren (um z.B. vorherzusagen, welche primär angeklickt werden).\n",
    "\n",
    "Schauen wir uns zunächst an, wie viele Überschriften es gibt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df[\"title\"].map(str) != ''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie erwartet gibt es keine Artikel, die keine oder leere Überschriften haben. \n",
    "\n",
    "Betrachten wir noch die grobe mittlere Anzahl der Tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_length\"] = [len(t.split(\" \")) for t in df[\"title\"]]\n",
    "df[\"title_length\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Im Mittel sind das also etwa 8 Tokens, damit kann man schon einiges analysieren. Einer Analyse würde also nichts im Wege stehen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Überschriften und Einleitungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das gleich Verfahren können wir nun für die Überschriften mit den Einleitungen anwenden. Das wäre z.B. dann sinnvoll, wenn du durch ein *Eye Tracking* herausgefunden hast, dass die Leser meistens nur die Einleitung lesen, nicht aber den Rest der Meldung.\n",
    "\n",
    "Gibt es Meldungen, die keine Einleitung haben?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df[\"header\"].map(str) == ''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Glück gibt es solche Meldungen auch nicht.\n",
    "\n",
    "Berechnen wir noch die mittlere Anzahl der Tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_header_length\"] = [len(t.split(\" \")) for t in (df[\"title\"]+\" \"+df[\"header\"])]\n",
    "df[\"title_header_length\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das sind im Mittel schon 27 Tokens. Mit dieser Datenmenge kannst du auch sehr gut arbeiten und damit Erkenntnisse ableiten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gesamte Meldungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die gesamtem Meldungen sind bereits linguistisch analysiert. Die Anzahl der Tokens sind schon berechnet, die kannst du direkt auswerten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"no_tokens\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Texte sind *deutlich* länger und ihre Analyse wird daher wesentlich aufwändiger, aber bestimmt auch mehr Erkenntnisse hervorbringen. Eine solche Analyse ist aber nur dann sinnvoll, wenn du sichergehen kannst, dass die Leser auch die gesamte Meldung lesen werden. Sonst erzeugst du dadurch einen sog. *Bias*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einzelne Absätze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oft wirst du Texten begegnen, deren Absätze relativ unabhängig voneinander sind und unterschiedliche Themen behandeln. Bei diesen ist es dann sinnvoll, die Absätze separat voneinander zu analysieren.\n",
    "\n",
    "Die Absätze sind mit `\\n` voneinander getrennt und können so auch zerlegt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = [p for text in df[\"text\"] for p in text.split(\"\\n\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie viele Absätze gibt es insgesamt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auswertungsentitäten richtig wählen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei der Wahl der richtigen Granularität für die Auswertung solltest du dir intensiv Gedanken machen. Überlege, was du erreichen willst. Du kannst das zwar später noch umstellen, aber eine richtige Wahl am Anfang spart erheblich Zeit und Ärger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
