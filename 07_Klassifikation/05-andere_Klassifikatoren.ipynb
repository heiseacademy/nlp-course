{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klassifikation mit anderen Klassifikatoren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Teil wirst du kennenlernen, welche anderen Klassifikatoren es in `scikit-learn` noch gibt und wie sich diese bei der Vorhersage der Autoren verhalten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einladen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie gewohnt lädst du die linguistisch analysierten Daten ein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    os.system(\"test -f heise-articles-2020.db || wget  https://datanizing.com/heiseacademy/nlp-course/blob/main/99_Common/heise-articles-2020.db.gz && gunzip heise-articles-2020.db.gz\")\n",
    "    newsticker_db = 'heise-articles-2020.db'\n",
    "else:\n",
    "    newsticker_db = '../99_Common/heise-articles-2020.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 \n",
    "import pandas as pd\n",
    "\n",
    "sql = sqlite3.connect(newsticker_db)\n",
    "df = pd.read_sql(\"SELECT * FROM nlp_articles WHERE datePublished<'2021-01-01' ORDER BY datePublished\", \n",
    "                 sql, index_col=\"id\", parse_dates=[\"datePublished\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle diese Felder kommen damit prinzipiell als Kategorien in Frage. Betrachte sie nun nacheinander:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten für Autoren-Klassifikation vorbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Vorhersage der Autoren hat schon mit dem `SVC`-Modell sehr gut funktioniert. Deshalb wendest du dieses Beispiel nun auch auf die anderen Klassifikatoren an. Die Vorbereitung der Daten ist genau wie vorher:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du bestimmst zunächst die Top-Autoren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_authors = df.groupby(\"author\").count().sort_values(\"title\", ascending=False).head(20)[[\"title\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit du zu einer ausgeglichenen Trainingsmenge kommst, suchst du den Top-Autor mit den wenigsten Artikeln:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_articles = min(top_authors[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun konstruierst du einen `DataFrame`, der von allen Autoren gleich viele Artikel enthält:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = pd.concat([df[df[\"author\"] == author].sample(min_articles, random_state=42)\n",
    "                     for author in top_authors.index.values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun kannst du die Daten vektorisieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from spacy.lang.de.stop_words import STOP_WORDS as stop_words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words, min_df=2)\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(adf[\"nav\"])\n",
    "tfidf_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allgemeine Klassifikation und Vorhersage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um es dir etwas einfacher zu machen, die Vorhersagen der Modelle zu bewerten, schreibst du dir eine kleine Hilfsfunktion, ide den Klassifikator trainiert, die Vorhersage durchführt und die anzeigt, wie häufig die Vorhersage mit der Wahrheit übereinstimmt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train_and_predict(clf, X, y):\n",
    "    clf.fit(X, y)\n",
    "    predicted = clf.predict(X)\n",
    "    print(np.unique(y == predicted, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der *Naive Bayes*-Klassifikator ist sehr einfach, du kannst ihn extrem schnell trainieren und das Ergebnis ist einigermaßen ordentlich. *Naive Bayes* wird häufig als sog. *Baseline* verwendet - alles Anderes sollte eigentlich besser sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "train_and_predict(MultinomialNB(), tfidf_vectors, adf[\"author\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Gegensatz zu dem Namen, der nach Regression klingt, kannst du den *Logistic Regression* auch zur Klassifikation verwenden. Die Ergebnisse sind besser als bei Naive Bayer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "train_and_predict(LogisticRegression(), tfidf_vectors, adf[\"author\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der *SGDClassifier* ist eine SVM, die mit einem linearen Kernel arbeitet. Das Ergebnis ist fast zu gut und sieht nach \"auswendig lernen\" aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "train_and_predict(SGDClassifier(loss=\"hinge\"), tfidf_vectors, adf[\"author\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Decision Tree* baut eine Kaskade von ja/nein-Entscheidungen auf und versucht damit, aus den Daten zu lernen. Auch das sieht nach \"auswendig\" aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "train_and_predict(DecisionTreeClassifier(), tfidf_vectors, adf[\"author\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Random Forest* ist eine sog. *Ensemble-Methode* aus vielen Decision Trees. Auch hier liegt der Verdacht nahe, dass das Modell nur auswendig gelernt hat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "train_and_predict(RandomForestClassifier(), tfidf_vectors, adf[\"author\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Gradient Boost*  ist eine Ensemble-Methode, bei der die Gewichtung der einzelnen Klassifikatoren dynamisch angepasst wird. Auch dieser Algorithmus hat vermutlich auswendig gelernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "train_and_predict(GradientBoostingClassifier(), tfidf_vectors, adf[\"author\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K nearest neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*K nearest neighbors* klassifiziert einen unbekannten Punkt immer mit der Mehrheit (z.B. 5 bei k=5) der Punkte, zu denen die direkt umliegenden Punkte gehören. Der Algorithmus funktioniert in hochdimensionalen Räumen leider nicht sonderlich gut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "train_and_predict(KNeighborsClassifier(), tfidf_vectors, adf[\"author\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wahl des richtigen Klassifikators ist entscheidend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie du siehst, ist die Performance der unterschiedlichen Klassifikatoren sehr verschieden.\n",
    "\n",
    "Noch besser bewerten kannst du das, wenn du die Performance-Metriken kennst."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
