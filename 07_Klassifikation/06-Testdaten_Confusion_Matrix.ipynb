{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testdaten und Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Teil beschäftigst du dich damit, wie du die Abstraktionsfähigkeit eines Modells und damit seine Vorhersagequalität messen kannst.\n",
    "\n",
    "Bisher hast du \"nur\" überprüft, wie gut das Modell das gelernte *reproduzieren konnte*. Jetzt wirst du echte Vorhersagen mit unbekannten Daten durchführen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einladen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie gewohnt lädst du die linguistisch analysierten Daten ein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    os.system(\"test -f heise-articles-2020.db || wget  https://datanizing.com/heiseacademy/nlp-course/blob/main/99_Common/heise-articles-2020.db.gz && gunzip heise-articles-2020.db.gz\")\n",
    "    newsticker_db = 'heise-articles-2020.db'\n",
    "else:\n",
    "    newsticker_db = '../99_Common/heise-articles-2020.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 \n",
    "import pandas as pd\n",
    "\n",
    "sql = sqlite3.connect(newsticker_db)\n",
    "df = pd.read_sql(\"SELECT * FROM nlp_articles WHERE datePublished<'2021-01-01' ORDER BY datePublished\", \n",
    "                 sql, index_col=\"id\", parse_dates=[\"datePublished\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Teil betrachtest du nur die Klassifikation nach Autoren. Genauso kannst du das natürlich für Keywords (einzeln!) oder für die Kommentare durchführen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten für Autoren-Klassifikation vorbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du bestimmst zunächst die Top-Autoren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_authors = df.groupby(\"author\").count().sort_values(\"title\", ascending=False).head(20)[[\"title\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle Autoren sollen gleich viele Artikel erhalten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_articles = min(top_authors[\"title\"])\n",
    "adf = pd.concat([df[df[\"author\"] == author].sample(min_articles, random_state=42)\n",
    "                     for author in top_authors.index.values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun kannst du die Daten vektorisieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from spacy.lang.de.stop_words import STOP_WORDS as stop_words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words, min_df=2)\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(adf[\"nav\"])\n",
    "tfidf_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun möchtest du das Datenset in zwei voneinander unabhängige teilen:\n",
    "1. Die *Trainingsdaten* dienen dem Modell zum Training. Mit diesen Daten soll es lernen und seine Abstraktionsfähigkeit erlangen.\n",
    "2. Die *Testdaten*, mit denen du das gelernte verifizierst.\n",
    "\n",
    "Wichtig: Sowohl die Trainings- als auch die Testdaten müssen schon vorgelabelt sein, d.h. du musst das richtige Ergebnis kennen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Den Split in Trainings- und Testdaten kannst du mit der Funktion `train_test_split` von `scikit-learn` durchführen. Dieser Funktion übergibst du die Vektoren und die Ergebnisse. Außerdem kannst du noch angeben, wie viele Daten du im Trainingsset haben willst (hier 75%). Der `random_state` dient der Reproduzierbarkeit, das kennst du schon.\n",
    "\n",
    "Eine Schwierigkeit kommt jetzt noch dazu: du musst darauf achten, dass von jedem Autor der gleiche Anteil in den Trainings- und Testdaten liegt, sonst ist das Training wenig ausgewogen. Dazu nutzt du den `stratify`-Parameter, um das Datenset fair ([stratifiziert](https://de.wikipedia.org/wiki/Geschichtete_Zufallsstichprobe)) aufzubauen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(tfidf_vectors, adf[\"author\"].values, \n",
    "                                                      train_size=0.75, random_state=42,\n",
    "                                                      stratify=adf[\"author\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training und Auswertung SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Training läuft nun (annhähernd) so, wie du es schon kennst. Es gibt einen kleinen Unterschied, du trainierst das Modell nur mit den Trainingsdaten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svc = svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt kannst du sowohl die Ergebnisse für die Trainings- als auch für die Testdaten vorhersagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = svc.predict(X_train)\n",
    "pred_test  = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun wird es spannend! Wie hat sich das Modell in der Klassifikation der Trainingsdaten geschlagen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.unique(pred_train == y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das hat wie erwartet sehr gut funktioniert mit nur sechs Fehlern.\n",
    "\n",
    "Schau dir nun die Ergebnisse bei den Testdaten an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pred_test == y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das ist ein erheblicher Unterschied und deutet auf ein auswendig gelerntes Modell hin (sog. (Overfitting)[https://de.wikipedia.org/wiki/%C3%9Cberanpassung]).\n",
    "\n",
    "Damit ist die echte Vorhersagekraft des Modells leider nicht so gut, wie du (vielleicht) ursprünglich gedacht hast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verteilung der Fehler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie verteilen sich die Fehler in den klassifizierten Daten des Datensets? Eigentlich müssten alle Autoren gleich häufig vorkommen. Das kannst du relativ einfach ermitteln:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = pd.DataFrame(pred_test, columns=[\"author\"])\n",
    "pt[\"count\"] = 1\n",
    "pt.groupby(\"author\").count().plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das ist nicht *fair*, `Tilman Wittenhorst` hat bei weitem zu viele Artikel zugeordnet bekommen!\n",
    "\n",
    "Um herauszufinden, wie sich die Fehler verteilen, kannst du die sog. [Confusion Matrix](https://de.wikipedia.org/wiki/Beurteilung_eines_bin%C3%A4ren_Klassifikators#Wahrheitsmatrix:_Richtige_und_falsche_Klassifikationen) berechnen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, pred_test, labels=top_authors.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In den Zeilen stehen die echten Ergebnisse, in den Spalten die vorhergesagten. Einen Treffer findest du also auf der Diagonalen.\n",
    "\n",
    "Das ist schön, aber leider *sehr unübersichtlich*. Mithilfe von `seaborn` kannst du das viel besser in einer Heatmap darstellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(confusion_matrix(y_test, pred_test, labels=top_authors.index.values), \n",
    "            xticklabels=top_authors.index.values, yticklabels=top_authors.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du siehst, dass `Tilman Wittenhorst` sehr oft vorhergesagt wurde, aber leider auch sehr häufig falsch. Das würde auch deiner Erwartung entsprechen, die du nach dem Balkendiagramm oben hast.\n",
    "\n",
    "Mit anderen Klassifikatoren erzielst du andere, möglicherweise auch bessere Ergebnisse. Das kannst du einfach durch den Austausch der Klassifikatoren oben erreichen (aus dem letzten Notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix vermittelt Einsicht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anhand der Confusion Matrix siehst du gut, wo der Klassifikator *daneben liegt*. Allerdings eignet sich die Matrix noch nicht gut als Maß für die Performance, weil viel zu viele Einzelwerte vorhanden sind.\n",
    "\n",
    "Eine Lösung dafür lernst du in den nächsten Kapiteln kennen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
