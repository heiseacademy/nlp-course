{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid-Search und Parameter-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du hast nun bereits Gütekriterien für Machine Learning-Verfahren kennengelernt und mit der Kreuzvalidierung gearbeitet, um die Stabilität der Modelle bewerten zu können.\n",
    "\n",
    "Die Verfahren haben allerdings noch mehr Parameter. So kannst du auch an der Vektorisierung Änderungen vornehmen oder überlegen, welches überhaupt geeignete Textfelder für die Klassifikation sind. Dies wird unter dem Begriff *Hyperparameter* zusammengefasst, die du jetzt optimieren wirst."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einladen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie gewohnt lädst du die linguistisch analysierten Daten ein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    os.system(\"test -f heise-articles-2020.db || wget  https://datanizing.com/heiseacademy/nlp-course/blob/main/99_Common/heise-articles-2020.db.gz && gunzip heise-articles-2020.db.gz\")\n",
    "    newsticker_db = 'heise-articles-2020.db'\n",
    "else:\n",
    "    newsticker_db = '../99_Common/heise-articles-2020.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 \n",
    "import pandas as pd\n",
    "\n",
    "sql = sqlite3.connect(newsticker_db)\n",
    "df = pd.read_sql(\"SELECT * FROM nlp_articles WHERE datePublished<'2021-01-01' ORDER BY datePublished\", \n",
    "                 sql, index_col=\"id\", parse_dates=[\"datePublished\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Teil betrachtest du nur die Klassifikation nach Autoren. Genauso kannst du das natürlich für Keywords (einzeln!) oder für die Kommentare durchführen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten für Autoren-Klassifikation vorbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diesen Teil kennst du schon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_authors = df.groupby(\"author\").count().sort_values(\"title\", ascending=False).head(20)[[\"title\"]]\n",
    "\n",
    "min_articles = min(top_authors[\"title\"])\n",
    "adf = pd.concat([df[df[\"author\"] == author].sample(min_articles, random_state=42)\n",
    "                     for author in top_authors.index.values])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Den Split in Trainings- und Testdaten führt der Algorithmus später selbst durch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline und Parameter Range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weil du Parameter sowohl in der Vektorisierung als auch im Modell optimieren möchtest, fasst du das in einer sog. `Pipeline` zusammen. Die Pipeline erhält als Input die Texte und gibt dir als Ergebnis den Autor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from spacy.lang.de.stop_words import STOP_WORDS as stop_words\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "text_pipe = Pipeline([(\"vect\", TfidfVectorizer(stop_words=stop_words)),\n",
    "                     (\"clf\", SGDClassifier(loss='hinge', max_iter=1000, tol=1e-3, random_state=42))\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn du keine eigene Methode angibst, werden die Daten automatisch stratifiziert mit `StratifiedKFold`. Das ist genau das, was du brauchst, deswegen brauchst du dich nicht weiter damit zu beschäftigen.\n",
    "\n",
    "Genau überlegen musst du dir allerdings, welche Parameter du modizifieren bzw. durchsuchen möchtest. Dafür gibt es eine Konvention, und zwar gibst du als Präfix immer den Kurznamen des Pipeline-Schritts oben an, hinter zwei `__` kommt dann der zu variierende Parameter selbst als Schlüssel mit einem Tupel und den auszuprobierenden Werten als Wert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"vect__min_df\": (2, 5, 10),\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2)),  \n",
    "    \"vect__use_idf\": (True, False), \n",
    "    \"vect__sublinear_tf\": (True, False),\n",
    "    \"clf__alpha\": (0.0001, 0.0002)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Fall würdest du also `3*2*2*2*2 = 48` Kombinationen ausprobieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch mit Wiederholungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Stabilität zu überprüfen, führt `GridSearchCV` jeden Durchlauf dreimal mit unterschiedlichen Zusammensetzungen aus Trainings- und Testdaten durch. Damit ergeben sich 144 Durchläufe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(text_pipe, parameters, n_jobs=-1, cv=3, verbose=1, return_train_score=True)\n",
    "grid_search.fit(adf[\"nav\"], adf[\"author\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lass dir die besten Resultate ausgeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bester Score (hier Accuracy): %0.3f\" % grid_search.best_score_)\n",
    "\n",
    "print(\"Bestes Parameter Set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ergebnis ist etwas überraschen, weil nämlich IDF gar nicht verwendet wird! Auch Bigramme scheinen keine Verbesserung zu bringen.\n",
    "\n",
    "Du kannst dir die Resultate auch noch genauer in einem `DataFrame` darstellen lassen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_).sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie du siehst, liegen die Ergebnisse sehr dicht beeinander. Resultat 28 mit IDF liegt z.B. nur wenig vom Optimum entfernt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `full_text` als alternatives Feld?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du kannst jetzt alternativ mit dem gleichen Verfahren auc noch ein anderes Feld ausprobieren. z.B. den `full_text`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(text_pipe, parameters, n_jobs=-1, cv=3, verbose=1, return_train_score=True)\n",
    "grid_search.fit(adf[\"full_text\"], adf[\"author\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lass dir die Ergebnisse anzeigen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bester Score (hier Accuracy): %0.3f\" % grid_search.best_score_)\n",
    "\n",
    "print(\"Bestes Parameter Set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das hat wesentlich besser funktioniert als die bisherige Klassifikation. Offenbar ist die Lemmatisierung und Konzentration auf bestimmte Wortarten der Autoren-Klassifikation abträglich."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifikation und Detail-Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt kannst du dir die Ergebnisse nochmal genau anschauen und für die oben gefundenen Parameter ein Training und eine Klassifikation durchführen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words, min_df=10, sublinear_tf=True, use_idf=False)\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(adf[\"full_text\"])\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(tfidf_vectors, adf[\"author\"].values, \n",
    "                                                      train_size=0.75, random_state=42,\n",
    "                                                      stratify=adf[\"author\"].values)\n",
    "\n",
    "clf = SGDClassifier(loss='hinge', max_iter=1000, tol=1e-3, alpha=0.0002, random_state=42)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Führe nun die Vorhersage durch und betrachte die Ergebnisse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pred_test = clf.predict(X_test)\n",
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das sieht schon sehr gut aus, mit einem solchen Ergebnis kannst du fast immer zufrieden sein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-Search automatisiert Optimierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit einer Grid-Search kannst du versuchen, die Performance eines Klassifikators zu verbessern, in dem du stur alle möglichen Kombinationen der sog. *Hyperparameter* ausprobieren lässt. Das ist zwar nicht besonders effizient, funktioniert aber ziemlichh gut.\n",
    "\n",
    "Wie du gesehen hast, waren die Ergebnisse bei der Autoren-Klassifikation sehr überraschend. Du hättest vorher bestimmt nicht gedacht, dass der Volltext ein besseres Ergebnis produziert als die linguistisch analysierten Texte. Erkläbar ist es trotzdem, nämlich mit dem Schreibstil der Autoren, der natürlich im Volltext am deutlichsten zutage tritt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
