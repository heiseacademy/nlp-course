{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation und Holdout-Verfahren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du hast nun bereits Gütekriterien für Machine Learning-Verfahren kennengelernt. In dem von dir stratifizierten Datenset kannst du z.B. die Accuracy verwenden.\n",
    "\n",
    "Allerdings könnte genau diese Accuracy (wie auch Precision und Recall) von der Art und Weise abhängen, wie du das Datenset in Trainings- und Testdaten aufgeteilt hast. Ein gutes Modell sollte davon unabhängig sein. Deswegen wirst du jetzt versuchen, unterschiedliche Splits auszuprobieren und die Stabilität des Modells damit testen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einladen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie gewohnt lädst du die linguistisch analysierten Daten ein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    os.system(\"test -f heise-articles-2020.db || wget  https://datanizing.com/heiseacademy/nlp-course/blob/main/99_Common/heise-articles-2020.db.gz && gunzip heise-articles-2020.db.gz\")\n",
    "    newsticker_db = 'heise-articles-2020.db'\n",
    "else:\n",
    "    newsticker_db = '../99_Common/heise-articles-2020.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 \n",
    "import pandas as pd\n",
    "\n",
    "sql = sqlite3.connect(newsticker_db)\n",
    "df = pd.read_sql(\"SELECT * FROM nlp_articles WHERE datePublished<'2021-01-01' ORDER BY datePublished\", \n",
    "                 sql, index_col=\"id\", parse_dates=[\"datePublished\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Teil betrachtest du nur die Klassifikation nach Autoren. Genauso kannst du das natürlich für Keywords (einzeln!) oder für die Kommentare durchführen:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten für Autoren-Klassifikation vorbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diesen Teil kennst du schon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_authors = df.groupby(\"author\").count().sort_values(\"title\", ascending=False).head(20)[[\"title\"]]\n",
    "\n",
    "min_articles = min(top_authors[\"title\"])\n",
    "adf = pd.concat([df[df[\"author\"] == author].sample(min_articles, random_state=42)\n",
    "                     for author in top_authors.index.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from spacy.lang.de.stop_words import STOP_WORDS as stop_words\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words, min_df=2)\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(adf[\"nav\"])\n",
    "tfidf_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch zur Berechnung der Qualitätsmetriken benötigst du einen Split in Trainings- und Testdaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training und Auswertung SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Aufteilung in Trainings- und Testdaten wird automatisch stratifiziert durchgeführt mit `StratifiedKFold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(random_state=42)\n",
    "scores = cross_val_score(clf, tfidf_vectors, adf[\"author\"].values, scoring=\"accuracy\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf, tfidf_vectors, adf[\"author\"].values, scoring=\"precision_macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Möchtest du mehrere Scores auf einmal ausrechnen, ist das auch möglich. Dazu musst du allerdings die Funktion `cross_validate` verwenden, die dir auch noch mehr Ergebnisse zurückliefert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "clf = SGDClassifier(random_state=42)\n",
    "cv = cross_validate(clf, tfidf_vectors, y=adf[\"author\"].values, \n",
    "                    scoring=(\"accuracy\", \"precision_weighted\", \"recall_weighted\"))\n",
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die identischen Werte für `test_accuracy` und `test_recall_weighted` sind auf den ersten Blick erstaunlich - das liegt aber an der Konstruktion unseres \"ausgeglichenen\" Trainingssets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Stabilität des Klassifikators erkennst du z.B. gut am Verhältnis zwischen Mittelwert und Standardabweichung, das sollte nicht zu groß sein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv['test_accuracy'].std() / cv['test_accuracy'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vergleich der Klassifikatoren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genau wie du im letzten Teil die Güte der Klassifikatoren ermittelt hast, kannst du nun ihre Stabilität überprüfen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "for clf_class in [SVC, SGDClassifier, MultinomialNB, \n",
    "                  DecisionTreeClassifier, RandomForestClassifier]:\n",
    "    clf = clf_class(random_state=42) if clf_class != MultinomialNB else clf_class()\n",
    "    print(clf_class.__name__)\n",
    "    cv = cross_validate(clf, tfidf_vectors, y=adf[\"author\"].values, \n",
    "                         scoring=(\"accuracy\", \"precision_weighted\", \"recall_weighted\"))\n",
    "    for m in [\"accuracy\", \"precision_weighted\", \"recall_weighted\"]:\n",
    "        print(m, cv[f'test_{m}'].mean(), cv[f'test_{m}'].std() / cv[f'test_{m}'].mean())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdout-Verfahren zeigt dir die Stabilität eines Klassifikators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mithilfe des Holdout-Verfahrens und der Kreuzvalidierung kannst du schnell unterschiedliche Konfigurationen von Trainings- und Testdaten erzeugen und damit die Stabilität deines Modells testen.\n",
    "\n",
    "Eine Überprüfung ist zwar etwas langwierig, du solltest sie aber unbedingt durchführen. Nur so kannst du sicherstellen, dass deine Ergebnisse auch valide sind."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
