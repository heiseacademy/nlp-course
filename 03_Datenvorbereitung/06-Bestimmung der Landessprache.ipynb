{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bestimmung der Landessprache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In den folgenden Kapiteln werden wir uns mit der *linguistischen Analyse* beschäftigen. Dort geht es um Satzbau, Wortarten usw. Die Analysemethoden bzw. die dazu verwendeten Modelle sind abhängig von der verwendeten Landessprache.\n",
    "\n",
    "Nicht alle Dokumente eines *Korpus* müssen unbedingt in der gleichen Landessprache verfasst sein. Mehrsprachige Auswertungen sind zwar möglich, aber an sehr vielen Stellen musst du vorsichtig sein (z.B. beim Zählen der Worthäufigkeiten). Deswegen solltest du im ersten Schritt für jedes Dokument die Landessprache bestimmen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nutzung von fastText Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noch vor relativ kurzer Zeit war die Bestimmung der Landessprache eines Dokuments wirklich *schwierig*. Es gab fast schon esoterische Ansätze (ZIP-Dateien mit Texte in verschiedenen Sprachen bauen und Größen vergleichen!), die aber auch nicht richtig funktioniert haben.\n",
    "\n",
    "In der Zwischenzeit ist das Problem größtenteils gelöst - und das auch noch sehr elegant. Mithilfe von *Word Embeddings* (die du später noch genauer kennenlernen wirst).\n",
    "\n",
    "Dankenswerterweise gibt es schon vortrainierte Modelle, die du einfach herunterladen kannst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "model_filename = \"lid.176.ftz\"\n",
    "r = requests.get(f\"https://dl.fbaipublicfiles.com/fasttext/supervised-models/{model_filename}\")\n",
    "open(model_filename, 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt kannst du das `fasttext`-Modul importieren und das Modell laden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "lang_model = fasttext.load_model(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probiere es mit einigen Texten aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_model.predict(\"comment tu t'appelles?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_model.predict(\"what's your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_model.predict(\"wie heißt du?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Ergebnis erhältst du jeweils eine Liste der erkannten Sprache und eine mit deren Wahrscheinlichkeiten. In der Standardeinstellung liefert dir `predict` immer nur einen einzigen Vorschlag, das kannst du aber umstellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_model.predict(\"comment tu t'appelles?\", k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine Liste der [ISO-639-1-Sprachabkürzungen](https://de.wikipedia.org/wiki/Liste_der_ISO-639-1-Codes) hilft dir bei der Interpretation. *Latein* kannst du z.B. in den allermeisten Fällen eher ausschließen.\n",
    "\n",
    "Die Wahrscheinlichkeiten für die Sprachen addieren sich zu `1.0`. Wenn z.B. der erste Vorschlag doppelt so wahrscheinlich ist wie der zweite, kannst du diesen auch akzeptieren - selbst wenn einer eine *relativ kleine Wahrscheinlichkeit hat*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein sehr gutes Beispiel für Texte in unterschiedlichen Sprachen findet sich auf http://crism.maden.org/dunno.html. Dort steht der Satz \"I don’t know. I only work here.\" in 63 Sprachen zur Verfügung. Zuerst lädst du die Datei herunter und übergibst sie an `BeautifulSoup`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(requests.get(\"http://crism.maden.org/dunno.html\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mithilfe der bisher erklärten Technologien kannst du den Text inkl. der richtigen Antworten aus dem HTML extrahieren. Die Texte stehen alle in `<p class=\"translation\">`-Tags, die richtigen Antworten in dem Attribut `lang`. Eine Vorhersage wird als richtig gewertet, wenn die erste Sprache doppelt so wahrscheinlich wie die zweite ist. Sprachen, die mit `x-` beginnen, werden ausgeschlossen. Englisch hat kein `lang`-Attribute, das kannst du durch die Exception abfangen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "ok = not_ok = 0\n",
    "for p in soup.select(\"p.translation\"):\n",
    "    text = p.text.strip().replace(\"\\n\", \" \")\n",
    "    try:\n",
    "        correct = re.sub(r\"\\-.*\", \"\", p.attrs[\"lang\"])\n",
    "    except:\n",
    "        correct = \"en\"\n",
    "    if correct != 'x':\n",
    "        l = lang_model.predict(text, k=2)\n",
    "        # Hauptsprache doppelt so wahrscheinlich wie zweite Wahl?\n",
    "        if l[1][0] > 2*l[1][1]:\n",
    "            predict = l[0][0].replace(\"__label__\", \"\")\n",
    "            if predict == correct:\n",
    "                ok += 1\n",
    "            else:\n",
    "                print(f\"Fehler bei '{text}'\")\n",
    "                print(f\"sollte {correct} sein, {predict} vorhergesagt\")\n",
    "                not_ok += 1\n",
    "\n",
    "print(f\"ok = {ok}, not ok = {not_ok}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kurz zur Bewertung der Ergebnisse:\n",
    "\n",
    "* Walisisch `cy` wurde als Westfriesisch `fy` klassifiziert\n",
    "* `dk` ist im Text falsch kodiert, das Ergebnis ist richtig\n",
    "* Farsi `fa` wurde als Arabisch `ar` klassifiziert\n",
    "* Galizisch `gl` wurde als Portugiesisch `pt` klassifiziert\n",
    "* `got` und `ceb` sind keine gültigen Abkürzungen\n",
    "* Javanisch `jv` wurde als Englisch `en` klassifiziert\n",
    "* Norwegisch `nb` wurde als Dänisch `da` klassifiziert\n",
    "* Sächsisch `nds` wurde als Deutsch `de` klassifiziert\n",
    "* `se` ist im Text falsch kodiert, das Ergebnis ist richtig\n",
    "\n",
    "Abgesehen von etwas unüblichen Sprachen sind eigentlich nur die Fehlklassifikation von *Farsi* und evtl. *Javanisch* problematisch. `fasttext` arbeitet also sehr zuverlässig in der Sprachklassifikation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprachen vor der Analyse bestimmen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn du dir nicht ganz sicher bist, ob alle Dokumente deines Korpus in der gleichen Sprache verfasst sind (besonderes bei User Generated Content), solltest du die Erkennung der Landessprache immer am Anfang deiner Analyse durchführen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
