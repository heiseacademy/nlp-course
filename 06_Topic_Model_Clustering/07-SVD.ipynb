{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du hast jetzt bereits NMF und LDA zum Topic Modeling kennengelernt. Ein anderes Verfahren aus der linearen Algebra ist die sog. *Hauptachsentranformation* und davon abgeleitet die *Singulärwertzerlegung*. Da diese vielfältig eingesetzt werden kann, schauen wir uns die auch noch an und bewerten abschließend die unterschiedlichen Verfahren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einladen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie gewohnt lädst du die linguistisch analysierten Daten ein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    os.system(\"test -f heise-articles-2020.db || wget  https://datanizing.com/heiseacademy/nlp-course/blob/main/99_Common/heise-articles-2020.db.gz && gunzip heise-articles-2020.db.gz\")\n",
    "    newsticker_db = 'heise-articles-2020.db'\n",
    "else:\n",
    "    newsticker_db = '../99_Common/heise-articles-2020.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 \n",
    "import pandas as pd\n",
    "\n",
    "sql = sqlite3.connect(newsticker_db)\n",
    "df = pd.read_sql(\"SELECT * FROM nlp_articles WHERE datePublished<'2021-01-01' ORDER BY datePublished\", \n",
    "                 sql, index_col=\"id\", parse_dates=[\"datePublished\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend führst du die Vektorisierung durch. Das kann auch wieder einen Augenblick dauern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.de.stop_words import STOP_WORDS as stop_words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words, min_df=5, use_idf=False)\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(df[\"nav\"])\n",
    "tfidf_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch die Nutzung von `min_df=5` ist die Matrix einigermaßen übersichtlich geblieben!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Model mit SVD berechnen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Aufrufsyntax des Topic Models ist sehr ähnlich zu der des `TfidfVectorizers`, nur dass du hier keine Transformation durchführen musst, daher heißt die Methode nur `fit`. Der Aufruf kann ein paar Sekunden dauern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "num_topics = 10\n",
    "\n",
    "svd = TruncatedSVD(n_components = num_topics)\n",
    "svd.fit(tfidf_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie gewohnt zeigst du die Topics an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topics_table(model, feature_names, n_top_words = 20):\n",
    "    word_dict = {}\n",
    "    \n",
    "    for i in range(model.n_components):\n",
    "        # ermittle für jedes Topic die größten Werte\n",
    "        words_ids = model.components_[i].argsort()[:-n_top_words-1:-1]\n",
    "        words = [feature_names[key] for key in words_ids]\n",
    "        # und füge die entsprechenden Worte im Klartext dem Dictionary hinzu\n",
    "        word_dict['Topic #%02d' % i] = words;\n",
    "    \n",
    "    return pd.DataFrame(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_table(svd, tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ergebnis sieht schon ziemlich gut aus. Abgesehen von dem ersten Topic (#00) sind alle ziemlich gut interpretierbar! Im Gegensatz zu den anderen Verfahren unterscheiden sich die wichtigsten Wörter der Topics häufig nicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svd.singular_values_ / svd.singular_values_.sum() * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "def wordcloud_topic_model_summary(model, feature_names, no_top_words):\n",
    "    for topic in model.components_:\n",
    "        freq = { feature_names[i].replace(\" \", \"_\"): topic[i] for i in topic.argsort()[:-no_top_words - 1:-1]}\n",
    "        wc = WordCloud(background_color=\"white\", max_words=100, width=960, height=540)\n",
    "        wc.generate_from_frequencies(freq)\n",
    "        plt.figure(figsize=(12,12))\n",
    "        plt.imshow(wc, interpolation='bilinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die weniger differenzierten Topics siehst du auch in den Wordclouds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wordcloud_topic_model_summary(svd, tfidf_vectorizer.get_feature_names(), 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMF, LDA oder lieber doch SVD?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So berechtigt diese Frage ist, so schwer ist sie zu beantworten. In den allermeisten Fällen wird NMF schon ziemlich gute Resultate liefern. SVD ist hauptsächlich aus konzeptionellen Gründen und zur Dimensionsreduktion interessant. Bei LDA ist es schwer zu entscheiden, ob der deutlich höhere Rechenaufwand durch das Sampling wirklich gerechtfertig ist.\n",
    "\n",
    "Du kannst dich auch zwischen `scikit-learn` und `gensim` entscheiden. Während ersteres das bessere API hat und sich leichter auch für überwachte Lernverfahren einsetzen lässt, kann letzteres mehr Methoden und insbesondere auch *Scores* ausrechnen, leidet aber etwas unter seinem API. Es schadet keinesfalls, wenn du dich mit beidem vertraut machst!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Models werden oft vergessen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei unüberwachten Lernverfahren denkt man meistens an *Clustering*, was aber für (lange) Texte nur eingeschränkt einsatzfähig ist. Topic Models sind häufig schneller zu berechnen und du solltest sie unbedingt in dein Analyse-Portfolio aufnehmen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
