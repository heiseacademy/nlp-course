{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coherence-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In den vergangenen Teilen hast du unterschiedliche Algorithmen zur Berechnung von Topic Models kennengelernt. Du hattest das Gefühl, dass sich die NMF-Modelle besser interpretieren lassen als die LDA-Modelle. Aber stimmt das auch? Kann man das messen? Dafür gibt es den sog. *Coherence Score*, der die Güte eines Modells misst.\n",
    "\n",
    "Die Zahl von zehn Topics ist auch vom Himmel gefallen. Das kannst du zwar als Konvention nutzen und einfach mal ausprobieren. Aber ein etwas strukturierteres Vorgehen wäre hier schon auch gut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einladen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie gewohnt lädst du die linguistisch analysierten Daten ein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    os.system(\"test -f heise-articles-2020.db || wget  https://datanizing.com/heiseacademy/nlp-course/blob/main/99_Common/heise-articles-2020.db.gz && gunzip heise-articles-2020.db.gz\")\n",
    "    newsticker_db = 'heise-articles-2020.db'\n",
    "else:\n",
    "    newsticker_db = '../99_Common/heise-articles-2020.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 \n",
    "import pandas as pd\n",
    "\n",
    "sql = sqlite3.connect(newsticker_db)\n",
    "df = pd.read_sql(\"SELECT * FROM nlp_articles WHERE datePublished<'2021-01-01' ORDER BY datePublished\", \n",
    "                 sql, index_col=\"id\", parse_dates=[\"datePublished\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nutzung von `gensim`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gensim` ist eine auf Topic Models spezialisierte Bibliothek, die du später auch noch für Word Embeddings nutzen wirst.\n",
    "\n",
    "Die Daten musst du für `gensim` etwas manueller vorbereiten. Du benötigst ein geschachteltes Array, in dem für jedes Dokument die Wörter bereits getrennt in Listen stehen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"gensim>=4.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.de.stop_words import STOP_WORDS as stop_words\n",
    "import regex as re\n",
    "# create tokenized documents\n",
    "gensim_words = [[w for w in re.split(r'[\\|\\#]', doc.lower()) if w not in stop_words] \n",
    "                           for doc in df[\"nav\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit kann dir `gensim` ein `Dictionary` erzeugen (es nummeriert dabei die Wörter):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "dictionary = Dictionary(gensim_words) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ähnlich wie bei `scikit-learn` kannst du Daten ausfiltern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=5, no_above=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und schließlich die Dokumente vektorisieren. Hier nutzt du das Bag-of-words-Modell, weil du LDA als Methode nutzen möchtest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = [dictionary.doc2bow(doc) for doc in gensim_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schließlich kannst du das Topic Model berechnen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "lda = LdaModel(corpus=bow, id2word=dictionary, num_topics=10, \n",
    "                      iterations=400, passes=20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie du schon weißt, benötigt NMF die Vektoren im Tfidf-Format. Das kann `gensim` auch für dich ausrechnen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import TfidfModel\n",
    "tfidf_model = TfidfModel(bow)\n",
    "tfidf = tfidf_model[bow]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt kannst du von `gensim` das NMF-Modell berechnen lassen. Um ein zu `scikit-learn` vergleichbares Modell zu erreichen, kannst du die Parameter noch etwas anpassen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.nmf import Nmf\n",
    "nmf = Nmf(corpus=tfidf, num_topics=10, id2word=dictionary, \n",
    "          w_max_iter=200,  h_max_iter=200, passes=20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das sieht ganz ähnlich aus, gut!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coherence Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Berechnung der Kohärenz eines Topic Models ist ziemlich kompliziert (vielleicht auch ein Grund, wrum das in `scikit-learn` nicht implementiert ist). Dabei arbeitet de Algorithmus auch mit *Wortähnlichkeiten*, damit musst du dich aber zum Glück nicht beschäftigen.\n",
    "\n",
    "Je höher der Score ist, desto besser ist das Modell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "lda_coherence = CoherenceModel(model=lda, texts=gensim_words, dictionary=dictionary, coherence='c_v')\n",
    "lda_score = lda_coherence.get_coherence()\n",
    "lda_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_coherence = CoherenceModel(model=nmf, texts=gensim_words, dictionary=dictionary, coherence='c_v')\n",
    "nmf_score = nmf_coherence.get_coherence()\n",
    "nmf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Fall bestätigt dich der Score - die besser interpretierbare Variante hat auch den höheren Score. Das muss nicht immer so sein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimale Anzahl an Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir hatten die Anzahl der Topics relativ beliebig auf 10 gesetzt. Im Moment weißt du nicht, ob das der optimale Wert ist. Aber du kannst den *Coherence Score* für unterschiedliche viele Topics ausrechnen.\n",
    "\n",
    "Üblicherweise wächst der Score mit  der Anzahl er Topics. Ein *lokales Maximum* ist ein guter Kandidat dafür, die richtig Anzahl von Topics gefunden zu haben. Jetzt musst du etwas Geduld haben, die Berechnung dauert ein knappe halbe Stunde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "res = []\n",
    "for num_topics in tqdm(range(5, 20)):\n",
    "    lda = LdaModel(corpus=bow, id2word=dictionary, num_topics=num_topics, \n",
    "                      iterations=400, passes=20, random_state=42)\n",
    "    lda_coherence = CoherenceModel(model=lda, texts=gensim_words, dictionary=dictionary, coherence='c_v')\n",
    "    lda_score = lda_coherence.get_coherence()\n",
    "    res.append({ \"num_topics\": num_topics, \"score\": lda_score })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_num = pd.DataFrame(res)\n",
    "lda_num.set_index(\"num_topics\").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ergebnis sieht bei 13 Topics am besten aus. Kannst du das auch am besten interpretieren?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda13 = LdaModel(corpus=bow, id2word=dictionary, num_topics=13, \n",
    "                      iterations=400, passes=20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda13.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Tat sieht das schon deutlich besser aus, auch wenn `Apple` und `Google` immer noch sehr eng miteinander verbunden sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Führe die gleiche Übung nochmal mit NMF durch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for num_topics in tqdm(range(5, 20)):\n",
    "    nmf = Nmf(corpus=tfidf, num_topics=num_topics, id2word=dictionary, \n",
    "              w_max_iter=200,  h_max_iter=200, passes=20, random_state=42)\n",
    "    nmf_coherence = CoherenceModel(model=nmf, texts=gensim_words, dictionary=dictionary, coherence='c_v')\n",
    "    nmf_score = nmf_coherence.get_coherence()\n",
    "    res.append({ \"num_topics\": num_topics, \"score\": nmf_score })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_num = pd.DataFrame(res)\n",
    "nmf_num.set_index(\"num_topics\").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier scheint elf eine bessere Anzahl zu sein. Probier es aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf11 = Nmf(corpus=tfidf, num_topics=11, id2word=dictionary, \n",
    "            w_max_iter=200,  h_max_iter=200, passes=20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf11.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sieht schon etwas besser aus, allerdings taucht Google nun gar nicht mehr auf! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coherence Scores zur Erklärung von Topic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leider werden die Coherence Scores nicht besonders häufig verwendet. Sie können dir aber helfen, dich zwischen unterschiedlichen Topic Models zu entscheiden.\n",
    "\n",
    "Außerdem kannst du Coherence Scores nutzen, um die optimale Menge an Topics zu finden. Allerdings solltest du dich dann auf ziemlich lange Rechenzeiten einstellen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
