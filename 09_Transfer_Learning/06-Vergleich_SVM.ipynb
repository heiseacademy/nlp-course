{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klassifikation mit Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie  gesehen hast, hat die Vorhersage erfolgreicher Artikel mit BERT sehr gut funktioniert.\n",
    "\n",
    "Allerdings ist der dazu notwendige Rechenaufwand ziemlich erheblich. Ohne Grafikkarten dauert das mehrere Stunden. Deshalb solltest du dich in solchen Fälle fragen, ob du mit einfacheren Methoden nicht auch ein ähnlich gutes Ergebnis erzielen kannst. Das ist besonders dann wichtig, wenn du das Modell noch weiter skalieren willst (und z.B. die Newsticker-Meldungen von einem Jahrzehnt betrachten willst).\n",
    "\n",
    "Hier wirst du daher die BERT-Ergebnisse mit einer einfachen SVM vergleichen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einladen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um möglichst die gleichen Voraussetzungen zu schaffen, betrachtest du nur die Titel selbst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    os.system(\"test -f heise-articles-2020.db || wget  https://datanizing.com/heiseacademy/nlp-course/blob/main/99_Common/heise-articles-2020.db.gz && gunzip heise-articles-2020.db.gz\")\n",
    "    newsticker_db = 'heise-articles-2020.db'\n",
    "else:\n",
    "    newsticker_db = '../99_Common/heise-articles-2020.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 \n",
    "import pandas as pd\n",
    "\n",
    "sql = sqlite3.connect(newsticker_db)\n",
    "df = pd.read_sql(\"SELECT id, datePublished, title, commentCount FROM articles \\\n",
    "                    WHERE datePublished<'2021-01-01' ORDER BY datePublished\", \n",
    "                 sql, index_col=\"id\", parse_dates=[\"datePublished\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten für Klassifikation vorbereiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst normalisierst du die Kommentare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"normalizedCommentCount\"] = df[\"commentCount\"].fillna(0).map(int)\n",
    "df.loc[df[\"normalizedCommentCount\"]>500, \"normalizedCommentCount\"] = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dann konstruierst du zwei `DataFrame`, in denen erfolgreich und nicht erfolgreiche Posts enthalten sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_success = df[df[\"normalizedCommentCount\"]>50].copy()\n",
    "df_success[\"success\"] = 1\n",
    "\n",
    "df_no_success = df[df[\"normalizedCommentCount\"]<10].copy()\n",
    "df_no_success[\"success\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du berechnest die Größe des kleineren `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_success = min(len(df_success), len(df_no_success))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und erzeugst ein ausgeglichenes Trainingsset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = pd.concat([df_success.sample(min_success, random_state=42),\n",
    "                 df_no_success.sample(min_success, random_state=42)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vektorisieren und trainieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Daten vektorisierst du nun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=2, ngram_range=(1,2))\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(sdf[\"title\"])\n",
    "tfidf_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Performance messen zu können, teilst du die Daten wie gewohnt in ein Trainings- und Testdatenset auf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(tfidf_vectors, sdf[\"success\"].values, \n",
    "                                                      train_size=0.75, random_state=42,\n",
    "                                                      stratify=sdf[\"success\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schließlich trainierst du das Modell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(random_state=42)\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorhersagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die Testdaten lässt du die Vorhersagen berechnen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pred_test  = svc.predict(X_test)\n",
    "np.unique(pred_test == y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufgrund des ausgeglichenen Datensets ist die Accuracy ein gutes Maß für die Abstraktionsfähigkeit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ergebnis sieht fast genauso gut aus wie im Falle der BERT-Klassfikation.\n",
    "\n",
    "Lass dir jetzt noch den Report ausgeben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicht immer muss also ein komplexes Modell tatsächlich so viel besser sein!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Es muss nicht immer *Deep Learning* sein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie du gesehen hast, kann man auch einen herkömmlichen Klassifikator so trainieren, dass er eine ähnlich gute Performance wie ein wirklich komplex Sprachmodell erreicht.\n",
    "\n",
    "Das ist selbstverständlich nicht für alle Aufgaben der Fall. In vorliegenden Fall klappt das gut, weil vermutlich einige *Buzzwords* darüber entscheiden, wie viele Kommentare ein Artikel erhält. Bei anderen Fragestellungen, in denen der Kontext eine größere Rolle spielt, können Transfer Learning Modelle sehr viel besser funktionieren als klassisches Machine Learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
