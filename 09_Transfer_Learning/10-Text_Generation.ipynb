{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Abschluss des Kurses schaust du dir jetzt noch an, wie ein Algorithmus Texte selbst erzeugen kann. Das ist ziemlich überraschend, allerdings sind die Anwendungsmöglichkeiten im Vergleich zu der Textanalyse etwas eingeschränkt. Ab und zu ergeben jedoch auch ziemlich lustige Resultate und vielleicht hast du ja genau dafür einen Anwendungsfall!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch wenn ein riesiges Modell hinter der Texterzeugung steht, ist der Aufruf geradezu grotesk einfach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_name = \"dbmdz/german-gpt2\"\n",
    "#model_name = \"dbmdz/german-gpt2-faust\"\n",
    "pipe = pipeline('text-generation', model=model_name,\n",
    "                 tokenizer=model_name, device=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ähnlich wie bei BERT gibt es auch bei diesem Transfer-Learning sehr viele Zufallszahlengeneratoren, die du wegen der Reproduzierbarkeit der Ergebnisse alle einheitlich initialisierst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "# alle Zufallszahlengeneratoren initialisieren (Reproduzierbarkeit)\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du beginnst mit einem *sehr offenen Satz*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pipe(\"Der Sinn des Lebens ist es\", max_length=100)[0][\"generated_text\"]\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Text ist vielleicht nicht extrem sinnvoll, aber er hat die *Stimmung* des Anfangssatzes aufgenommen. Sehr interessant.\n",
    "\n",
    "Versuche es nun mit einem Satz, der *Spannung auslösen soll*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pipe(\"Plötzlich wachte ich auf\", max_length=400)[0][\"generated_text\"]\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch dieses Ergebnis ist *mindestens interessant*. Der Text ist etwas unzusammenhängend und man hat das Gefühl, dass das Modell einige Wörter dann plötzlich so gut findet, dass es sie ständig wiederholt. Andererseits werden bestimmte Assoziationen (Nacht, schlafen usw.) doch ganz gut aufgenommen.\n",
    "\n",
    "Schließlich kannst du noch *einen technischen Text* ausprobieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pipe(\"Ich experimentiere gerade mit automatischer Text-Erzeugung\", max_length=100)[0][\"generated_text\"]\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch hier wurde die Richtung des Textes sehr gut aufgenommen und da System hat versucht, einen Text mit Fachbegriffen zu schreiben. Wie sinnvoll die tatsächlich sind, sei dahingestellt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Generation steht noch am Anfang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Beispiele haben eher lustige als tatsächlich verwendbare Text produziert.\n",
    "\n",
    "Allerdings steht mit GPT-3 ein wesentlich leistungsfähigeres System zur Verfügung, mit dem schon viel bessere Resultate generiert werden können. Neue Resultate ermöglichen es außerdem, aus Texten Bilder zu erstellen, was auch schon zu guten (und teils überraschenden) Ergebnissen führt.\n",
    "\n",
    "Auf jeden Fall lohnt es sich, wenn du solche Technologien weiter beobachtest."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
