{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantische Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du kennst jetzt unterschiedliche Word Embeddings und kannst damit Ähnlichkeiten zwischen Wörtern selbst bestimmen.\n",
    "\n",
    "Allerdings gehen die Möglichkeiten der Embeddings noch weiter darüber hinaus. So kannst du eine Kombination von TF/IDF und Embeddings nutzen, um Texte in einen \"semantischen Raum\" zu transformieren und dort auch Ähnlichkeiten von Wörtern (oder Konzepten) ermitteln sowie semantische Suchen durchführen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einladen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie gewohnt lädst du die linguistisch analysierten Daten ein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    os.system(\"test -f heise-articles-2020.db || wget  https://datanizing.com/heiseacademy/nlp-course/blob/main/99_Common/heise-articles-2020.db.gz && gunzip heise-articles-2020.db.gz\")\n",
    "    newsticker_db = 'heise-articles-2020.db'\n",
    "else:\n",
    "    newsticker_db = '../99_Common/heise-articles-2020.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 \n",
    "import pandas as pd\n",
    "\n",
    "sql = sqlite3.connect(newsticker_db)\n",
    "df = pd.read_sql(\"SELECT * FROM nlp_articles WHERE datePublished<'2021-01-01' ORDER BY datePublished\", \n",
    "                 sql, index_col=\"id\", parse_dates=[\"datePublished\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten vektorisieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit du  häufige Wörter niedriger gewichten kannst, berechnest du zunächst die TF/IDF-Vektoren der Dokumente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from spacy.lang.de.stop_words import STOP_WORDS as stop_words\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words, min_df=10, sublinear_tf=True, use_idf=False)\n",
    "tfidf_vectors = tfidf_vectorizer.fit_transform(df[\"nav\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wortvektoren berechnen (bzw. einladen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend lädst du die bereits berechneten Word Embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ON_COLAB:\n",
    "    os.system(\"test -f heise-articles-2020.w2v || wget  https://datanizing.com/heiseacademy/nlp-course/blob/main/99_Common/heise-articles-2020.w2v.gz && gunzip heise-articles-2020.w2v.gz\")\n",
    "    w2v_file = \"heise-articles-2020.w2v\"\n",
    "else:\n",
    "    w2v_file = \"../99_Common/heise-articles-2020.w2v\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"gensim>=4.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cwinkler/.venv/jupyter-new/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "w2v = KeyedVectors.load_word2vec_format(w2v_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stattdessen könntest du auch ein fertiges Embedding nutzen, wenn deine Datenmenge zu klein ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantische Tranformation durchführen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion zur semantischen Transformation ist etwas komplizierter.\n",
    "\n",
    "* Du beginnst mit einer leeren Liste gemittelter Dokumentvektoren\n",
    "* Du iterierst zunächst über alle TF/IDF-Vektoren (`shape[0]` gibt dir die Anzahl der Zeilen), also über alle Dokumente\n",
    "* Du setzt den gemittelten Wortvektor des aktuellen Dokuments auf 0\n",
    "* Anschließend lässt du dir die Spalten ausgeben, die Werte != 0 haben (das entsprechende Wort kommt im Dokument vor)\n",
    "* Wenn sich das Wort auch im Embedding-Vokabular befindet, addierst du den (normierten!) Wortvektor gewichtet mit dem TF/IDF-Maß\n",
    "* Falls sich ein gemittelter Wortvektor ungleich des Nullvektors ergeben hat, wird er normiert\n",
    "* Anschließend fügst du den Wortvektor in die Liste der gemittelten Dokumentvektoren an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10403/10403 [01:44<00:00, 99.25it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# averaged word vectors\n",
    "awv = []\n",
    "fn = tfidf_vectorizer.get_feature_names()\n",
    "for i in tqdm(range(tfidf_vectors.shape[0])):\n",
    "    v = np.zeros(w2v.vector_size)\n",
    "    # immer nur eine Zeile, rows wird nicht benötigt\n",
    "    rows,cols = tfidf_vectors[i].nonzero()\n",
    "    for c in cols:\n",
    "        feature = fn[c]\n",
    "        if feature in w2v.key_to_index :\n",
    "            # TF/IDF als Gewicht des normierten Wortvektors\n",
    "            wv = w2v[feature]\n",
    "            v += tfidf_vectors[i][0, c] * wv / np.linalg.norm(wv)\n",
    "    if np.linalg.norm(v) > 0:\n",
    "        v = v/np.linalg.norm(v)\n",
    "    awv.append(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun kannst du Ähnlichkeiten berechnen, dazu nutzt du die dir schon bekannte Methode `cosine_similarity`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Möchtest du z.B. die Dokumente finden, die die größte *semantische Ähnlichkeit* zu `apple` haben, kannst du zunächst den Vektor bestimmen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = w2v[\"apple\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend berechnest du den Cosinus-Abstand zu allen Dokumenten (die Funktion erwartet zwei Matrizen, daher ist der zweite Vektor in `[]`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = cosine_similarity(awv, [apple])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dich interessiert nur das Dokument mit der größten Ähnlichkeit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title             Apple TV+ und iTunes künftig auch auf LG-Ferns...\n",
       "header            Die Apple-TV-App soll nicht nur für Fernseher ...\n",
       "author                                                  Nico Jurran\n",
       "text              LG hat bekanntgegeben, die Apple-TV-App auf se...\n",
       "keywords                                Apple TV, CES, CES 2020, LG\n",
       "url               https://www.heise.de/newsticker/meldung/Apple-...\n",
       "datePublished                                   2020-01-07 08:03:00\n",
       "commentCount                                                     16\n",
       "full_text         Apple TV+ und iTunes künftig auch auf LG-Ferns...\n",
       "nouns             Apple|TV+|iTunes|LG-Fernsehern#Apple-TV-App|Fe...\n",
       "adjectives        künftig|auch#nur|auch#erst|darüber|direkt|zwar...\n",
       "verbs             soll|kommen|werden|nachrüsten#haben|bekanntgeb...\n",
       "lemmas            Apple|TV+|und|iTunes|künftig|auch|auf|LG-Ferns...\n",
       "nav               Apple|TV+|iTunes|künftig|auch|LG-Fernsehern#Ap...\n",
       "entities          Apple TV+|iTunes|LG-Fernsehern#Apple-TV-App#Ap...\n",
       "noun_chunks       Apple TV+|iTunes|LG-Fernsehern#Die Apple-TV-Ap...\n",
       "no_tokens                                                     169.0\n",
       "no_sentences                                                   14.0\n",
       "no_noun_chunks                                                 36.0\n",
       "Name: 2818639, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[r.argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spannend wird es jetzt, wenn du die Wortvektoren unterschiedlicher Wörter kombinierst. Da die Wortvektoren nicht normiert sind, musst du das noch nachholen, weil sonst verschiedene Wörter unterschiedlich stark beitragen würden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title             Einnahmeschätzung: App-Store-Umsatz fast doppe...\n",
       "header            Apples Anwendungsladen soll im dritten Quartal...\n",
       "author                                                   Ben Schwan\n",
       "text              Apple macht mit seinem App Store weiterhin her...\n",
       "keywords          Android, App Store, Apple, Apps, Einnahmen, Ge...\n",
       "url               https://www.heise.de/news/Einnahmeschaetzung-A...\n",
       "datePublished                             2020-10-05 17:48:00+02:00\n",
       "commentCount                                                    102\n",
       "full_text         Einnahmeschätzung: App-Store-Umsatz fast doppe...\n",
       "nouns             Einnahmeschätzung#App-Store-Umsatz|Google|Play...\n",
       "adjectives        fast|doppeln|so|hoch#dritt|erneut|fett#langsam...\n",
       "verbs             soll|schreiben|haben#wachsen#machen#sein#hochr...\n",
       "lemmas            Einnahmeschätzung|:#App-Store-Umsatz|fast|dopp...\n",
       "nav               Einnahmeschätzung#App-Store-Umsatz|fast|doppel...\n",
       "entities          App-Store-Umsatz|Google Play#Anwendungsladen#G...\n",
       "noun_chunks       Einnahmeschätzung#App-Store-Umsatz|Google Play...\n",
       "no_tokens                                                     293.0\n",
       "no_sentences                                                   26.0\n",
       "no_noun_chunks                                                 59.0\n",
       "Name: 2979597, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv =  w2v[\"google\"]/np.linalg.norm(w2v[\"google\"])\n",
    "wv += w2v[\"umsatz\"]/np.linalg.norm(w2v[\"umsatz\"])\n",
    "r = cosine_similarity(awv, [wv])\n",
    "df.iloc[r.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title                     Microsoft schließt Streaming-Portal Mixer\n",
       "header            Mit Mixer wollte Microsoft dem Amazon-Portal T...\n",
       "author                                                Daniel Herbig\n",
       "text              Microsofts Streaming-Portal Mixer schließt am ...\n",
       "keywords          Microsoft, Mixer, Spiele, Streaming-Dienst, Tw...\n",
       "url               https://www.heise.de/news/Microsoft-schliesst-...\n",
       "datePublished                             2020-06-23 09:29:00+02:00\n",
       "commentCount                                                     35\n",
       "full_text         Microsoft schließt Streaming-Portal Mixer\\nMit...\n",
       "nouns             Microsoft|Streaming-Portal#Mixer#Mixer|Microso...\n",
       "adjectives        Nun#22.#Auch|dort|weiterhin#Allerdings|nun|auc...\n",
       "verbs             schließen#wollen|bereit#soll|schließen|werden#...\n",
       "lemmas            Microsoft|schließen|Streaming-Portal#Mixer#\\n#...\n",
       "nav               Microsoft|schließen|Streaming-Portal#Mixer#Mix...\n",
       "entities          Microsoft|Streaming-Portal#Microsoft|Amazon-Po...\n",
       "noun_chunks       Microsoft|Streaming-Portal#Mixer#Mixer|Microso...\n",
       "no_tokens                                                     337.0\n",
       "no_sentences                                                   32.0\n",
       "no_noun_chunks                                                 79.0\n",
       "Name: 2916000, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv =  w2v[\"google\"]/np.linalg.norm(w2v[\"google\"])\n",
    "wv += w2v[\"umsatz\"]/np.linalg.norm(w2v[\"umsatz\"])\n",
    "wv += w2v[\"microsoft\"]/np.linalg.norm(w2v[\"microsoft\"])\n",
    "r = cosine_similarity(awv, [wv])\n",
    "df.iloc[r.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft schließt Streaming-Portal Mixer\n",
      "Mit Mixer wollte Microsoft dem Amazon-Portal Twitch Konkurrenz bereiten. Nun soll das Streaming-Portal geschlossen werden. Nutzer werden zu Facebook geschickt.\n",
      "Microsofts Streaming-Portal Mixer schließt am 22. Juli. Das hat Microsoft angekündigt. Nutzer des Streaming-Dienstes sollen nach dem Mixer-Aus zu Facebooks Alternative Facebook Gaming weitergeleitet werden.\n",
      "Auch die Mixer-Streamer sollen zu Facebook Gaming wechseln und dort weiterstreamen – Verträge sollen nach Möglichkeit weiterhin gelten. Allerdings haben die Streamer nun auch die Möglichkeit, davon zurückzutreten und zu anderen Plattformen zu gehen. Mixer-Nutzer, die noch Abonnements und Währungen für das Microsoft-Portal besitzen, sollen mit Xbox-Geschenkkarten entschädigt werden, schreibt Microsoft in einem Blog-Eintrag.\n",
      "Als Streaming-Portal mit Fokus auf Videospiele sollte Mixer vor allem Amazons Marktführer Twitch Konkurrenz bereiten. Das hat sich Microsoft viel kosten lassen: Beispielsweise hat das Unternehmen den beliebten Fortnite-Streamer Ninja exklusiv angeheuert. Die finanziellen Hintergründe des Vertrags sind unklar. EA soll vorher für einen einzigen Stream von Ninja eine Million US-Dollar gezahlt haben – das zeigt, um welche Summen es beim Exklusivvertrag zwischen Ninja und Mixer gehen könnte. Ninja hat noch nicht bekanntgegeben, ob er nun zu Facebook Gaming oder zurück zu Twitch wechselt.\n",
      "Zuletzt schloss Mixer sogar etwas zu Twitch auf, war im Großen und Ganzen aber dennoch abgeschlagen. Laut Marktforschern von Streamlabs und Newzoo wurden 2019 insgesamt knapp 10 Milliarden Stunden Stream-Inhalte bei Twitch geschaut, bei Mixer waren es nur 350 Millionen Stunden.\n",
      "Von der Zusammenarbeit mit Facebook erhofft sich Microsoft Unterstützung für den bevorstehenden Start des Cloud-Gaming-Dienstes xCloud, berichtet das Technikmagazin The Verge. Der Cloud-Gaming-Dienst von Microsoft soll in Facebook Gaming integriert werden, damit User zum Beispiel direkt über einen Link Spiele starten können – so macht es zum Beispiel auch Google mit Stadia und Youtube. Offenbar geht Microsoft davon aus, auf Facebook Gaming mehr Nutzer zu erreichen als auf Mixer möglich gewesen wären.\n",
      "Mixer startete 2016 zuerst unter dem Namen \"Beam\". Ein halbes Jahr nach dem Launch wurde die Plattform von Microsoft übernommen und umbenannt.\n",
      "(dahe)\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[r.argmax()][\"full_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantische Methoden durch Kombination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du hast gesehen, wie sich Word Embeddings mit \"traditionellen\" Machine Learning-Methoden kombinieren lassen.\n",
    "\n",
    "Das Ergebnis ist durchaus beeindruckend. Besonders im letzten Fall wird eine Meldung gefunden, in der das Wort \"Umsatz\" gar nicht vorkommt, die sich aber dennoch damit beschäftigt."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
