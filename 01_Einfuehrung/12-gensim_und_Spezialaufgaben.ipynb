{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Überblick über Basis-Tools: `gensim` und spezielle Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gensim` ist eine Python-Bibliothek, die  primär für Topic Models entwickelt wurde, kann aber auch gut für Word Embeddings umgehen.\n",
    "\n",
    "Mithilfe von PyLDAvis lassen sich Topic Modelle sehr intuitiv darstellen.\n",
    "\n",
    "Im letzten Teil des Kurses werden wir einige Deep Learning Bibliotheken verwenden, die für *Sprachmodelle* wie BERT und Question Answering verwendet werden können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das API ist von `gensim` ist etwas anders als bei `scikit-learn` und einige Aufgaben müssen *von Hand* erledigt werden. Wir können das Datenset mit den 20 Newsgroups von `scikit-learn` nutzen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Dictionary musst du bei `gensim` etwas aufwändiger aufgebauen, stark vereinfacht nutzt du Tokens, die durch den Tokenizier getrennt werden. Die *List Comprehensions* von Python machen deinen Code relativ kompakt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.utils import simple_tokenize\n",
    "\n",
    "posts = [post for post in newsgroups['data']]\n",
    "dict_voc = Dictionary([[word for word in simple_tokenize(post)] for post in posts]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anschließend kannst du mithilfe des Dictionaries die Texte in sog. *Bag of Words*-Vektoren wandeln:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = [dict_voc.doc2bow(simple_tokenize(post)) for post in posts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA (*Latent Dirichlet Allocation*) ist eine der beliebtesten Methoden zur Berechnung von Topic Models. Leider benötigt das Verfahren durch sog. *Sampling* sehr viel Zeit. Im Gegensatz zu `scikit-learn` unterstüzt `gensim` dabei mehrere Prozessoren, wenn du einen entsprechenden Computer hast (Grafikkarten werden leider noch nicht genutzt). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "lda = LdaMulticore(corpus=bow, id2word=dict_voc, chunksize=2000, iterations=400, num_topics=5, \n",
    "                   passes=20, eval_every=None, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ausgabe der Modelle kannst du etwas einfacher erreichen als mit `scikit-learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ergebnisse sind nicht gut interpretierbar, was an der *schlechten Tokenisierung* liegt. Topic Models werden daher auch oft zur Qualitätssicherung eingesetzt - sowohl für die Daten als auch für die Verarbeitungspipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bestimmt interessierst du dich jetzt dafür, wie trennscharf die Topics sind. Dafür gibt es ein eigenes Paket `pyLDAvis`, das die LDA-Modelle von `scikit-learn` und `gensim` direkt darstellen kann. Evtl. musst du das Paket zuerst installieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyLDAvis==3.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models\n",
    "\n",
    "lda_display = pyLDAvis.gensim_models.prepare(lda, bow, dict_voc)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie du sehen kannst, überlappen sich die Topic-Modelle in dieser auf zwei Dimensionen reduzierten Darstellung deutlich - ein Zeichen für eine schlechte Modellierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neben Topic Models kannst du `gensim` auch für *Word Embeddings* nutzen. Dabei wird jedem Wort ein Vektor zugeordnet, du benötigst dafür zwar keine vorklassifizierte Trainingsmenge, das Verfahren wird aber als *semi supervised* bezeichnet.\n",
    "\n",
    "Wir haben als Korpus den Heise-Newsticker benutzt und daraus word2vec-Embeddings berechnet. Die Embeddings lassen sich einfach laden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    os.system(\"test -f heise-articles-2020.w2v || wget https://datanizing.com/heiseacademy/nlp-course/blob/main/99_Common/heise-articles-2020.w2v.gz && gunzip heise-articles-2020.w2v.gz\")\n",
    "    newsticker_w2v = 'heise-articles-2020.w2v'\n",
    "else:\n",
    "    newsticker_w2v = '../99_Common/heise-articles-2020.w2v'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = gensim.models.KeyedVectors.load_word2vec_format(newsticker_w2v, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du kannst nun semantisch ähnliche Wörter bestimmen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.most_similar(\"apple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn du gerade nicht weißt, wie das Handy-Betriebssystem von *Google* heißt, sondern dir nur *iOS* von *Apple* einfällt, kann dir `word2vec` auch helfen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.most_similar(positive=[\"google\", \"ios\"], negative=[\"apple\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir werden uns später noch eingehend mit Embeddings und deren spannenden Möglichkeiten beschäftigen. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
