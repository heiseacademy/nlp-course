{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YNWuaDvyxgH5"
   },
   "source": [
    "# √úberblick √ºber Basis-Tools: `spacy` und `textacy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blo7tFzJxgIC"
   },
   "source": [
    "## spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTLyXGPLxgID"
   },
   "source": [
    "spaCy ist in der Zwischenzeit *das* Standard-Werkzeug f√ºr die linguistische Analyse. spaCy ist ein Open-Source-Projekt und stammt von der Berliner Firma explosion.ai\n",
    "\n",
    "Die Sprachmodelle sind mit tiefen neuronalen Netzen aufgebaut und auf gro√üe Datenmengen trainiert. Modelle stehen f√ºr viele Sprachen zur Verf√ºgung, insbesondere auch f√ºr Deutsch.\n",
    "\n",
    "spaCy musst du zun√§chst installieren und dazu passende Sprachmodelle herunterladen. Eine erste Analyse von Dokumenten scheint nicht viel zu ver√§ndern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBe3Qd0sxgIF"
   },
   "outputs": [],
   "source": [
    "!pip install textacy\n",
    "!python -m spacy download de_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pt0o3LGixgIG"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_lg\")\n",
    "d1 = \"Die Redaktionen der Heise Medien w√ºnschen ein friedliches und gesundes 2021.\"\n",
    "d2 = \"M√∂gen Ihre Hoffnungen erf√ºllt werden und Sie gesund bleiben oder werden.\"\n",
    "doc = nlp(d1 + \"\\n\" + d2)\n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkac7ZKkxgII"
   },
   "source": [
    "Tats√§chlich steckt in `doc` deutlich mehr, nur die Darstellung als `string` ist etwas spartanisch. Mithilfe von `pandas` kannst du die einzelnen Felder √ºbersichtlich in einer Tabelle darstellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3aBXxZwxgII",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "res = []\n",
    "for token in doc:\n",
    "    res.append([token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "                token.is_alpha, token.is_stop])\n",
    "\n",
    "pd.DataFrame(res, columns=[\"Text\", \"Lemma\", \"POS\", \"Tag\", \"Dep\", \"Alpha?\", \"Stop?\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZLnJktjxgIJ"
   },
   "source": [
    "Neben den Grundformen (Lemmas) sind die Abh√§ngigkeiten besonders interessant. Diese lassen sich auch grafisch visualisieren. spaCy bietet hier eine sehr sch√∂ne Integration in Jupyter an:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5xraTYYfxgIK"
   },
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "doc = nlp(d1)\n",
    "displacy.render(doc, style=\"dep\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yP_WJCB7xgIK"
   },
   "source": [
    "Das sieht schon sehr nach der Satzanalyse aus, die du bestimmt noch aus der Schule noch kennst. Nur erledigt hier zum Gl√ºck der Computer das Gros der Arbeit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Za64NxddxgIL"
   },
   "source": [
    "spaCy kann nat√ºrlich noch viel mehr, das soll dir hier nur ein bisschen Appetit auf die weiteren Lektionen machen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9ttzrfWxgIL"
   },
   "source": [
    "## textacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A77YwV3exgIL"
   },
   "source": [
    "`textacy` nutzt einige Funktionen von `spacy`, um daraus abgeleitete Informationen zu konstruieren.\n",
    "\n",
    "Bevor du eine Funktion selbst implementierst, ist es oft sinnvoll, erst mal bei `textacy` nachzuschauen, ob es die nicht schon gibt üòä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YSHpuKQ1xgIM"
   },
   "outputs": [],
   "source": [
    "import textacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geMcxZp1xgIN"
   },
   "source": [
    "Im ersten Schritt erzeugst du hier aus einem Text eine `spacy`-Dokument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y7LOE0OAxgIN"
   },
   "outputs": [],
   "source": [
    "de = textacy.load_spacy_lang(\"de_core_news_lg\")\n",
    "td1 = textacy.make_spacy_doc(d1, lang=de)\n",
    "td1._.preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qiBzctAKxgIN"
   },
   "source": [
    "Mit `textacy` kannst du dann sehr elegant sog *n-Gramme* (in diesem Fall Dreiwort-Kombinationen) ausrechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H6BDWO2ZxgIN"
   },
   "outputs": [],
   "source": [
    "list(textacy.extract.ngrams(td1, 3, filter_stops=True, filter_punct=True, filter_nums=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPf8c1ucxgIO"
   },
   "source": [
    "Mit `textacy` kannst du eine eigene Klasse f√ºr Statistik-Funktionen nutzen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzBqaV0_xgIO"
   },
   "outputs": [],
   "source": [
    "import textacy.text_stats\n",
    "ts = textacy.text_stats.TextStats(td1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGpwI50SxgIO"
   },
   "source": [
    "Und damit z.B. die Anzahl der W√∂rter, Silben und Buchstaben z√§hlen lassen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-5GD6xuxgIO"
   },
   "outputs": [],
   "source": [
    "ts.n_words, ts.n_syllables, ts.n_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLLCxI4LxgIP"
   },
   "source": [
    "Au√üerdem kannst du berechnen, wie einfach ein Text lesbar ist, dazu gibt es verschiedene Formeln. *Flesch-Kincaid* versucht die (amerikanische) Klassenstufe zu ermitteln, f√ºr die der Text geeignet ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bTQPz5-QxgIP"
   },
   "outputs": [],
   "source": [
    "ts.flesch_kincaid_grade_level, ts.flesch_reading_ease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vkEA0ImxgIP"
   },
   "source": [
    "## Es gibt noch mehr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bcn6CKhhxgIP"
   },
   "source": [
    "`spacy` und `textacy` k√∂nnen noch viel mehr. Hier siehst du schon, dass sich viele Routine-Aufgaben aus dem Deutschunterricht mit den Python-Bibliotheken sehr viel schneller erledigen lassen. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "10-spaCy_und_Textacy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
